# Analysis

## Layer 9, Head 6
Example Sentences: The news just brought a smile on my [MASK].
- The lightest and second lightest grids of "brought" are "news" and "smile". I think the model is able to learn that "news" and "smile" can be one of the subjects and objects of "brought" respectively, and it does see the relationship between these words.

## Layer 7, Head 5
Example Sentences: The news just brought a smile on my [MASK].
- "Smile" pays most attention to "brought", which appears that it can tell which word in the sentence kind of "trigger" or "lead to" itself.

## Layer 3, Head 2 
Example Sentences: The woman is so [MASK] that she attracts everyone.
- "Woman", "she" and "everyone" paying attention to "attract" and "attracts" paying attention to "woman" show that the model has figured out the relationship between these words. It seems to understand which words are the subject, verb and object.
- "Is" paying similar attention to "woman" and "attractive" displays exactly the idea of auxiliary verbs and subjective complement, that is the subject and subjective complement on either side of the auxiliary verb are equal to each other.